{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "rbKqh48OEN4t",
        "rn0iDOcParhl",
        "-A0jUrMFC404",
        "pjq5hGw32MWE"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Существует несколько библиотек для автоматического машинного обучения (AutoML) в Keras. Некоторые из них:\n",
        "\n",
        "*AutoKeras*: это библиотека AutoML, разработанная для Keras, которая автоматически определяет архитектуру нейронной сети и настраивает ее гиперпараметры. AutoKeras также предоставляет механизмы автоматического извлечения признаков и визуализации результатов.\n",
        "\n",
        "*Keras Tuner*: это библиотека для настройки гиперпараметров моделей Keras. Keras Tuner предоставляет механизмы для выбора лучшей комбинации гиперпараметров, включая случайный поиск, поиск сетки и байесовский поиск.\n",
        "\n",
        "*Talos*: это библиотека AutoML для Keras, которая использует байесовскую оптимизацию для выбора наилучших гиперпараметров модели. Talos также предоставляет механизмы автоматического создания отчетов и визуализации результатов.\n",
        "\n",
        "*Hyperas*: это библиотека для автоматической настройки гиперпараметров Keras с использованием поиска по сетке. Hyperas позволяет определить границы для гиперпараметров, которые нужно настроить, и выполняет автоматическую настройку на основе заданной функции оценки.\n",
        "\n",
        "Это не полный список, но эти библиотеки предоставляют множество возможностей для автоматической настройки моделей Keras."
      ],
      "metadata": {
        "id": "MAuu34rK8rfl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Подготовка и загрузка датасета с изображениями водителей"
      ],
      "metadata": {
        "id": "rbKqh48OEN4t"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gdown                                     # Подключение модуля для загрузки данных из облака\n",
        "import numpy as np                               # Библиотека работы с массивами\n",
        "import matplotlib.pyplot as plt                  # Для отрисовки графиков\n",
        "%matplotlib inline\n",
        "from PIL import Image                            # Для отрисовки изображений\n",
        "import random as random                          # Генератор рандомных чисел\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.optimizers import Adam                # Оптимизатор Adam\n",
        "from tensorflow.keras.models import Sequential   # Сеть прямого распространения\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization, GlobalAveragePooling2D, GlobalMaxPooling2D\n",
        "from tensorflow.keras import utils               # Используем для to_categorical\n",
        "from tensorflow.keras.preprocessing import image # Для отрисовки изображений\n",
        "from google.colab import files                   # Для загрузки своей картинки\n",
        "import os\n",
        "import time\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "jRH38OlEENRk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# указываем количество категорий правильных ответов\n",
        "category_count = 10\n",
        "# Загрузка zip-архива с датасетом из облака на диск виртуальной машины colab\n",
        "gdown.download('https://storage.yandexcloud.net/aiueducation/marketing/datasets/reality.zip', None, quiet=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXjrs5wiFFAC",
        "outputId": "d4caa806-5e05-473c-be80-1bc1932066d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'reality.zip'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Разархивация датасета в директорию 'content/cars'\n",
        "!unzip -qo \"reality.zip\" -d /content/reality\n",
        "\n",
        "# Папка с папками картинок, рассортированных по категориям\n",
        "IMAGE_PATH = '/content/reality/'"
      ],
      "metadata": {
        "id": "4uXNbn9vFWT-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Список с названиями категорий\n",
        "os.listdir(IMAGE_PATH)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DW8mStn8FFDT",
        "outputId": "f99a8f62-2890-4084-8815-e00f924a8d75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['safe_driving',\n",
              " 'drinking',\n",
              " 'texting_right',\n",
              " 'reaching_behind',\n",
              " 'operating_the_radio',\n",
              " 'texting_left',\n",
              " 'talking_on_the_phone_right',\n",
              " 'hair_and_makeup',\n",
              " 'talking_to_passenger',\n",
              " 'talking_on_the_phone_left']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Определение списка имен классов\n",
        "CLASS_LIST = sorted(os.listdir(IMAGE_PATH))\n",
        "\n",
        "# Определение количества классов\n",
        "CLASS_COUNT = len(CLASS_LIST)\n",
        "\n",
        "# Проверка результата\n",
        "print(f'Количество классов: {CLASS_COUNT}, метки классов: {CLASS_LIST}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYLOKYAcFFLW",
        "outputId": "11c617a2-f53a-4328-fb60-3397deac6602"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество классов: 10, метки классов: ['drinking', 'hair_and_makeup', 'operating_the_radio', 'reaching_behind', 'safe_driving', 'talking_on_the_phone_left', 'talking_on_the_phone_right', 'talking_to_passenger', 'texting_left', 'texting_right']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_files = []                           # Cписок путей к файлам картинок\n",
        "data_labels = []                          # Список меток классов, соответствующих файлам\n",
        "\n",
        "for class_label in range(CLASS_COUNT):    # Для всех классов по порядку номеров (их меток)\n",
        "    class_name = CLASS_LIST[class_label]  # Выборка имени класса из списка имен\n",
        "    class_path = IMAGE_PATH + class_name  # Формирование полного пути к папке с изображениями класса\n",
        "    class_files = os.listdir(class_path)  # Получение списка имен файлов с изображениями текущего класса\n",
        "    print(f'Размер класса {class_name} составляет {len(class_files)} изображений')\n",
        "\n",
        "    # Добавление к общему списку всех файлов класса с добавлением родительского пути\n",
        "    data_files += [f'{class_path}/{file_name}' for file_name in class_files]\n",
        "\n",
        "    # Добавление к общему списку меток текущего класса - их ровно столько, сколько файлов в классе\n",
        "    data_labels += [class_label] * len(class_files)\n",
        "\n",
        "print('Общий размер базы для обучения:', len(data_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lX2jNYhWFeDU",
        "outputId": "e35f3fc8-3bcb-4abd-894e-b62195821c11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размер класса drinking составляет 300 изображений\n",
            "Размер класса hair_and_makeup составляет 300 изображений\n",
            "Размер класса operating_the_radio составляет 300 изображений\n",
            "Размер класса reaching_behind составляет 300 изображений\n",
            "Размер класса safe_driving составляет 300 изображений\n",
            "Размер класса talking_on_the_phone_left составляет 300 изображений\n",
            "Размер класса talking_on_the_phone_right составляет 300 изображений\n",
            "Размер класса talking_to_passenger составляет 300 изображений\n",
            "Размер класса texting_left составляет 300 изображений\n",
            "Размер класса texting_right составляет 300 изображений\n",
            "Общий размер базы для обучения: 3000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_WIDTH = 64                           # Ширина изображения\n",
        "IMG_HEIGHT = 64                           # Высота изображения"
      ],
      "metadata": {
        "id": "xDIZkAocFhNC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_images = []                          # Пустой список для данных изображений\n",
        "\n",
        "for file_name in data_files:\n",
        "    # Открытие и смена размера изображения\n",
        "    img = Image.open(file_name).resize((IMG_WIDTH, IMG_HEIGHT)) \n",
        "    img_np = np.array(img)                # Перевод в numpy-массив\n",
        "    data_images.append(img_np)            # Добавление изображения в виде numpy-массива к общему списку\n",
        "\n",
        "x_data = np.array(data_images)            # Перевод общего списка изображений в numpy-массив\n",
        "y_data = np.array(data_labels)            # Перевод общего списка меток класса в numpy-массив\n",
        "\n",
        "print(f'В массив собрано {len(data_images)} фотографий следующей формы: {img_np.shape}')\n",
        "print(f'Общий массив данных изображений следующей формы: {x_data.shape}')\n",
        "print(f'Общий массив меток классов следующей формы: {y_data.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EXApfWMmFkom",
        "outputId": "850862cb-2a49-4e24-d046-188551a6cff8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "В массив собрано 3000 фотографий следующей формы: (64, 64, 3)\n",
            "Общий массив данных изображений следующей формы: (3000, 64, 64, 3)\n",
            "Общий массив меток классов следующей формы: (3000,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZ8s0Vj5FpJ1",
        "outputId": "64c42760-cc91-4602-d170-9c8ea3ad6056"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3000, 64, 64, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Нормированние массива изображений\n",
        "x_data = x_data / 255."
      ],
      "metadata": {
        "id": "dgDBDLbQFpMl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Делим данные на обучающую и проверочную выборки\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_data, y_data, test_size=0.05, random_state=42)"
      ],
      "metadata": {
        "id": "uDP_PekaFpSF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Задаем batch_size\n",
        "batch_size = 128\n",
        "\n",
        "# Загружаем названия классов из набора данных по водителям:\n",
        "classes=['drinking ', 'hair_and_makeup ', 'operating_the_radio ', 'reaching_behind ', 'safe_driving ', 'talking_on_the_phone_left  ', 'talking_on_the_phone_right  ', 'talking_to_passenger  ', 'texting_left  ', 'texting_right ']\n",
        "\n",
        "# Превращаем выходы сетей в формат  one hot encoding\n",
        "y_train = utils.to_categorical(y_train, category_count)\n",
        "\n",
        "pic_shapes = x_train[0].shape\n",
        "IMG_WIDTH = pic_shapes[0]\n",
        "IMG_HEIGHT = pic_shapes[1]\n",
        "num_channels = pic_shapes[2]\n",
        "\n",
        "# Делаем решейп\n",
        "x_train = x_train.reshape(x_train.shape[0], IMG_WIDTH, IMG_HEIGHT, num_channels)\n",
        "x_val = x_val.reshape(x_val.shape[0],IMG_WIDTH, IMG_HEIGHT, num_channels)"
      ],
      "metadata": {
        "id": "b_2TU_26FpU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_val = utils.to_categorical(y_val, category_count)"
      ],
      "metadata": {
        "id": "MP3oVQTIWQMF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(x_train.shape)\n",
        "print(x_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HdH9Bvo6FpXd",
        "outputId": "1f9e7702-0807-4951-9cd6-bec6ef29d29d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2850, 64, 64, 3)\n",
            "(150, 64, 64, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_train.shape)\n",
        "print(y_val.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3p2Qq3xUrtE",
        "outputId": "00192494-7cce-45a7-f47a-f2fe24b3e82c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2850, 10)\n",
            "(150, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AutoKeras"
      ],
      "metadata": {
        "id": "xyN1-gqr87t4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Auto-Keras (AutoML for deep learning) - это библиотека, предоставляющая возможность автоматизировать процесс создания глубоких нейронных сетей без участия человека. Она позволяет быстро и эффективно находить лучшие гиперпараметры модели на основе различных алгоритмов оптимизации и случайного поиска. Библиотека AutoKeras была выпущена в 2018 году.\n",
        "\n",
        "Библиотека может работать с изображениями, текстами и табличными данными.\n",
        "\n",
        "Основная идея Auto-Keras заключается в том, чтобы автоматически находить наиболее эффективные архитектуры глубоких нейронных сетей на основе процесса обучения с подкреплением (reinforcement learning). В процессе работы Auto-Keras генерирует случайные архитектуры сетей и оценивает их производительность на основе метрик, заданных пользователем. Затем происходит отбор лучших моделей и дальнейшая оптимизация гиперпараметров, таких как количество слоев, их тип, количество нейронов в каждом слое, функции активации и т.д.\n",
        "\n",
        "Auto-Keras использует набор примитивов, позволяющих генерировать различные архитектуры нейронных сетей, основанных на классических методах, таких как сверточные нейронные сети (Convolutional Neural Networks, CNN) и рекуррентные нейронные сети (Recurrent Neural Networks, RNN), а также на более современных методах, таких как ResNet и DenseNet. При этом процесс генерации новых моделей может занимать много времени и ресурсов.\n",
        "\n",
        "Auto-Keras поддерживает использование как CPU, так и GPU, что позволяет быстрее обрабатывать большие объемы данных. Кроме того, библиотека предоставляет удобный интерфейс для интеграции с другими библиотеками, такими как Keras и TensorFlow, что позволяет использовать уже готовые модели и переносить результаты между различными проектами."
      ],
      "metadata": {
        "id": "T3b1Z-lT81MV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Параметры:\n",
        "\n",
        "- **num_classes** Целое число (int). По умолчанию None. Если None, то оно будет получено из данных.\n",
        "- **multi_label** bool: Булев тип. По умолчанию установлено значение False.\n",
        "- **loss** Loss-функция Keras. По умолчанию используется 'binary_crossentropy' или 'categorical_crossentropy' в зависимости от количества классов.\n",
        "- **metrics** Необязательный параметр, может принимать список метрик Keras, в виде строки, функции или экземпляра метрики, список списков метрик или словарь с именованными метриками. По умолчанию используется метрика 'accuracy'..\n",
        "- **project_name** str: Строка. Название AutoModel. По умолчанию установлено значение 'image_classifier'.\n",
        "- **max_trials** int: Целое число. Максимальное количество разных моделей Keras, которые будут протестированы. Поиск может завершиться до достижения максимального количества проб. По умолчанию равен 100.\n",
        "- **directory** Optional[Union[str, pathlib.Path]]: Это строка. Путь к директории для сохранения результатов поиска. По умолчанию значение None, что создает папку с именем AutoModel в текущей директории.\n",
        "- **objective** str: String. Название метрики модели для минимизации или максимизации, например, 'val_accuracy'. По умолчанию устанавливается 'val_loss'.\n",
        "- **tuner** Optional[Union[str, Type[autokeras.engine.tuner.AutoTuner]]]: Строка или подкласс AutoTuner. Если строка, то должна быть одной из 'greedy', 'bayesian', 'hyperband' или 'random'. Она также может быть подклассом AutoTuner. Если не указано, то используется тюнер, специфичный для задачи, который сначала оценивает наиболее часто используемые модели для задачи, прежде чем исследовать другие модели.\n",
        "- **overwrite** bool: Булевое значение. По умолчанию False. Если False, загружает существующий проект с тем же именем, если такой найден. В противном случае перезаписывает проект.\n",
        "- **seed** Optional[int]: Это целочисленный параметр, который устанавливает случайное начальное значение для генератора случайных чисел, используемого во время обучения модели. Это позволяет воспроизводить результаты обучения на разных машинах и улучшает воспроизводимость результатов.\n",
        "- **max_model_size** Целое число. Максимальное количество скалярных параметров в модели. Модели, размер которых превышает это значение, отбрасываются.\n",
        "- **kwargs**: Этот параметр относится к конструктору AutoModel и позволяет указать любые аргументы, поддерживаемые этим классом. Класс AutoModel является базовым классом для всех поддерживаемых моделей в AutoKeras, таких как ImageClassifier, TextClassifier, StructuredDataClassifier, и другие. Конкретный список аргументов, поддерживаемых AutoModel, зависит от конкретного класса модели, который используется. В общем, аргументы могут включать в себя параметры для слоев, оптимизаторов, регуляризации и других компонентов модели."
      ],
      "metadata": {
        "id": "yLk0chu3PRft"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install autokeras"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvN4wCzPJc0B",
        "outputId": "83e876d3-7ec5-4a24-e90f-967720c6bb3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting autokeras\n",
            "  Downloading autokeras-1.1.0-py3-none-any.whl (148 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.6/148.6 KB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras-tuner>=1.1.0\n",
            "  Downloading keras_tuner-1.3.0-py3-none-any.whl (167 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.3/167.3 KB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from autokeras) (1.3.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from autokeras) (23.0)\n",
            "Requirement already satisfied: tensorflow>=2.8.0 in /usr/local/lib/python3.8/dist-packages (from autokeras) (2.11.0)\n",
            "Collecting keras-nlp>=0.4.0\n",
            "  Downloading keras_nlp-0.4.1-py3-none-any.whl (466 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m466.8/466.8 KB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from keras-nlp>=0.4.0->autokeras) (1.22.4)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.8/dist-packages (from keras-nlp>=0.4.0->autokeras) (1.4.0)\n",
            "Collecting tensorflow-text\n",
            "  Downloading tensorflow_text-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m85.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from keras-tuner>=1.1.0->autokeras) (2.25.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.8/dist-packages (from keras-tuner>=1.1.0->autokeras) (7.9.0)\n",
            "Collecting kt-legacy\n",
            "  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (2.2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (2.11.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (4.5.0)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (2.11.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (15.0.6.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (0.30.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (0.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (1.6.3)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (3.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (1.14.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (57.4.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (1.51.1)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (23.1.21)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (2.11.2)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (3.19.6)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.8.0->autokeras) (3.1.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->autokeras) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->autokeras) (2.8.2)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow>=2.8.0->autokeras) (0.38.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.8.0->autokeras) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.8.0->autokeras) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.8.0->autokeras) (3.4.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.8.0->autokeras) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.8.0->autokeras) (2.16.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.8.0->autokeras) (1.8.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner>=1.1.0->autokeras) (4.0.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (2.0.10)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (4.8.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (5.7.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (0.2.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (0.7.5)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m77.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner>=1.1.0->autokeras) (4.4.2)\n",
            "Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-text->keras-nlp>=0.4.0->autokeras) (0.12.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.8.0->autokeras) (0.2.8)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.8.0->autokeras) (5.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.8.0->autokeras) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow>=2.8.0->autokeras) (1.3.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython->keras-tuner>=1.1.0->autokeras) (0.8.3)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow>=2.8.0->autokeras) (6.0.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->keras-tuner>=1.1.0->autokeras) (0.2.6)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->ipython->keras-tuner>=1.1.0->autokeras) (0.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow>=2.8.0->autokeras) (3.14.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.8.0->autokeras) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow>=2.8.0->autokeras) (3.2.2)\n",
            "Installing collected packages: kt-legacy, jedi, tensorflow-text, keras-tuner, keras-nlp, autokeras\n",
            "Successfully installed autokeras-1.1.0 jedi-0.18.2 keras-nlp-0.4.1 keras-tuner-1.3.0 kt-legacy-1.0.4 tensorflow-text-2.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import autokeras as ak"
      ],
      "metadata": {
        "id": "h_4UkvN1Jc2k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "AutoKeras для многоклассовой классификации изображений на примере датасета с водителями\n",
        "\n",
        "- Параметр *multi_label* отвечает за тип задачи мульти-лейбл классификации. Если multi_label=True, то задача считается мульти-лейбл классификацией, в которой каждый объект может иметь несколько меток (классов) из множества возможных меток. Если multi_label=False (по умолчанию), то каждый объект имеет только одну метку из возможных.\n",
        "- *tuner* - алгоритм оптимизации (например, 'bayesian' или 'random');\n",
        " Он может принимать значения: 'greedy', 'bayesian', 'hyperband' или 'random'"
      ],
      "metadata": {
        "id": "OMK-XAuQbEfT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Эксперимент №1.**\n",
        "\n",
        "max_trials=5\n",
        "\n",
        "tuner='bayesian'"
      ],
      "metadata": {
        "id": "lG3Pfhh8mCgD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Обучение модели\n",
        "# Определение EarlyStopping-коллбека\n",
        "es_callback = EarlyStopping(monitor='val_loss', patience=4)\n",
        "start_time = time.time()\n",
        "clf = ak.ImageClassifier(overwrite=True, max_trials=5, num_classes=10, multi_label=False, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], \n",
        "                         project_name=\"my_project\", directory=\"my_dir\", seed=88, max_model_size=None, tuner='bayesian', objective ='val_accuracy')\n",
        "# Обучаем 10  моделей\n",
        "clf.fit(x_train, y_train, epochs=10, batch_size=64, callbacks=[es_callback])\n",
        "end_time = time.time()\n",
        "# Вывод времени обучения и точности модели\n",
        "print(\"Total training time:\", end_time - start_time)\n",
        "print(\"Training accuracy:\", clf.evaluate(x_train, y_train)[1])\n",
        "print(\"Test accuracy:\", clf.evaluate(x_val, y_val)[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLxGQQ-qJc7I",
        "outputId": "6a143973-80a6-4cf5-957c-64211527fc5a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 06m 15s]\n",
            "val_accuracy: 0.1190476194024086\n",
            "\n",
            "Best val_accuracy So Far: 0.26739928126335144\n",
            "Total elapsed time: 00h 28m 59s\n",
            "Epoch 1/10\n",
            "45/45 [==============================] - 12s 181ms/step - loss: 2.6213 - accuracy: 0.1042\n",
            "Epoch 2/10\n",
            "45/45 [==============================] - 8s 182ms/step - loss: 2.4515 - accuracy: 0.1070\n",
            "Epoch 3/10\n",
            "45/45 [==============================] - 8s 187ms/step - loss: 2.3876 - accuracy: 0.1298\n",
            "Epoch 4/10\n",
            "45/45 [==============================] - 9s 190ms/step - loss: 2.3277 - accuracy: 0.1386\n",
            "Epoch 5/10\n",
            "45/45 [==============================] - 8s 187ms/step - loss: 2.3239 - accuracy: 0.1632\n",
            "Epoch 6/10\n",
            "45/45 [==============================] - 8s 182ms/step - loss: 2.3005 - accuracy: 0.1512\n",
            "Epoch 7/10\n",
            "45/45 [==============================] - 8s 183ms/step - loss: 2.2427 - accuracy: 0.1723\n",
            "Epoch 8/10\n",
            "45/45 [==============================] - 8s 181ms/step - loss: 2.2260 - accuracy: 0.1747\n",
            "Epoch 9/10\n",
            "45/45 [==============================] - 8s 182ms/step - loss: 2.1952 - accuracy: 0.1884\n",
            "Epoch 10/10\n",
            "45/45 [==============================] - 8s 181ms/step - loss: 2.1661 - accuracy: 0.2011\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 53). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total training time: 1864.3755667209625\n",
            "90/90 [==============================] - 11s 98ms/step - loss: 2.1155 - accuracy: 0.3235\n",
            "Training accuracy: 0.32350876927375793\n",
            "5/5 [==============================] - 3s 227ms/step - loss: 2.0885 - accuracy: 0.3667\n",
            "Test accuracy: 0.36666667461395264\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# чтобы получить num_models лучших моделей:\n",
        "best_models = clf.tuner.get_best_models(num_models=3)"
      ],
      "metadata": {
        "id": "MIxMVIlR7tJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_models[0].summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1BFRMx978x2",
        "outputId": "494a38e0-b532-4022-f895-be139dda7f32"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
            "                                                                 \n",
            " cast_to_float32 (CastToFloa  (None, 64, 64, 3)        0         \n",
            " t32)                                                            \n",
            "                                                                 \n",
            " resizing (Resizing)         (None, 224, 224, 3)       0         \n",
            "                                                                 \n",
            " resnet50 (Functional)       (None, None, None, 2048)  23587712  \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 2048)             0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 2048)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                20490     \n",
            "                                                                 \n",
            " classification_head_1 (Soft  (None, 10)               0         \n",
            " max)                                                            \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 23,608,202\n",
            "Trainable params: 20,490\n",
            "Non-trainable params: 23,587,712\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_models[1].summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ov9WAFwU8DHb",
        "outputId": "f578b9a3-6c1a-490f-aa1e-88408ba9691e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
            "                                                                 \n",
            " cast_to_float32 (CastToFloa  (None, 64, 64, 3)        0         \n",
            " t32)                                                            \n",
            "                                                                 \n",
            " normalization (Normalizatio  (None, 64, 64, 3)        7         \n",
            " n)                                                              \n",
            "                                                                 \n",
            " random_flip (RandomFlip)    (None, 64, 64, 3)         0         \n",
            "                                                                 \n",
            " resizing (Resizing)         (None, 224, 224, 3)       0         \n",
            "                                                                 \n",
            " resnet152v2 (Functional)    (None, None, None, 2048)  58331648  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 100352)            0         \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 100352)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                1003530   \n",
            "                                                                 \n",
            " classification_head_1 (Soft  (None, 10)               0         \n",
            " max)                                                            \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 59,335,185\n",
            "Trainable params: 59,191,434\n",
            "Non-trainable params: 143,751\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_models[2].summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ngonEFfTaBF",
        "outputId": "5c0cf54e-bda9-42e3-fc79-d361d740946a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
            "                                                                 \n",
            " cast_to_float32 (CastToFloa  (None, 64, 64, 3)        0         \n",
            " t32)                                                            \n",
            "                                                                 \n",
            " efficientnetb0 (Functional)  (None, 2, 2, 1280)       4049571   \n",
            "                                                                 \n",
            " global_average_pooling2d (G  (None, 1280)             0         \n",
            " lobalAveragePooling2D)                                          \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 1280)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                12810     \n",
            "                                                                 \n",
            " classification_head_1 (Soft  (None, 10)               0         \n",
            " max)                                                            \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4,062,381\n",
            "Trainable params: 4,020,358\n",
            "Non-trainable params: 42,023\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Предсказываем на основании лучшей модели на проверочной выборке\n",
        "predicted_y = clf.predict(x_val)\n",
        "print(predicted_y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p83IJfRSJc-X",
        "outputId": "9cbebbf8-a92d-469a-ec22-39cc8eadd3f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 1s 103ms/step\n",
            "5/5 [==============================] - 0s 86ms/step\n",
            "[[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 1. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [1. 0. 0. ... 0. 0. 0.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Оцениваем лучшую модель с использованием тестовых данных.\n",
        "print(clf.evaluate(x_val, y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMOHGAARJdBM",
        "outputId": "ba6318b3-0afa-4021-91af-9a01ba27cbb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 2s 97ms/step - loss: 2.0885 - accuracy: 0.3667\n",
            "[2.0885496139526367, 0.36666667461395264]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Аккураси получилась низкой, для лучших результатов нужно сделать больше запусков, поменяв параметр max_trials"
      ],
      "metadata": {
        "id": "Mm4y8kc-fMM4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Эксперимент №2.**\n",
        "\n",
        "max_trials=15\n",
        "\n",
        "tuner='bayesian'"
      ],
      "metadata": {
        "id": "mgUYyTllmZVg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Запустим алгоритм на бОльшем количестве запусков и посмотрим, позволит ли это нам улучшить точность на проверочной выборке"
      ],
      "metadata": {
        "id": "WtCPcm3HB7Dp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Обучение модели\n",
        "# Определение EarlyStopping-коллбека\n",
        "es_callback = EarlyStopping(monitor='val_loss', patience=4)\n",
        "start_time = time.time()\n",
        "clf_2 = ak.ImageClassifier(overwrite=True, max_trials=15, num_classes=10, multi_label=False, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], \n",
        "                         project_name=\"my_project\", directory=\"my_dir\", seed=44, max_model_size=None, tuner='bayesian', objective ='val_accuracy')\n",
        "# Обучаем 10  моделей\n",
        "clf_2.fit(x_train, y_train, epochs=10, batch_size=64, callbacks=[es_callback], validation_data=(x_val, y_val))\n",
        "end_time = time.time()\n",
        "# Вывод времени обучения и точности модели\n",
        "print(\"Total training time:\", end_time - start_time)\n",
        "print(\"Training accuracy:\", clf_2.evaluate(x_train, y_train)[1])\n",
        "print(\"Test accuracy:\", clf_2.evaluate(x_val, y_val)[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rEz1SwAvE6a",
        "outputId": "e43f4890-da81-4f23-80c4-84f96eaeefb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 15 Complete [00h 12m 16s]\n",
            "val_accuracy: 0.10000000149011612\n",
            "\n",
            "Best val_accuracy So Far: 0.9200000166893005\n",
            "Total elapsed time: 01h 07m 14s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 105). These functions will not be directly callable after loading.\n",
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total training time: 4089.2154545783997\n",
            "90/90 [==============================] - 17s 157ms/step - loss: 0.1570 - accuracy: 0.9849\n",
            "Training accuracy: 0.9849122762680054\n",
            "5/5 [==============================] - 3s 149ms/step - loss: 0.3645 - accuracy: 0.9200\n",
            "Test accuracy: 0.9200000166893005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Да, эксперимент удался, точность повысилась до 92% на проверочной выборке. Посмотрим на архитектуру лучшей модели:"
      ],
      "metadata": {
        "id": "DLO-CoNmEZXr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_2 = clf_2.export_model()\n",
        "model_2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MJJqFMkPApIg",
        "outputId": "b6dcf1f4-d207-4ee1-b607-531e572e1726"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
            "                                                                 \n",
            " cast_to_float32 (CastToFloa  (None, 64, 64, 3)        0         \n",
            " t32)                                                            \n",
            "                                                                 \n",
            " resizing (Resizing)         (None, 224, 224, 3)       0         \n",
            "                                                                 \n",
            " resnet101v2 (Functional)    (None, None, None, 2048)  42626560  \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 100352)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                1003530   \n",
            "                                                                 \n",
            " classification_head_1 (Soft  (None, 10)               0         \n",
            " max)                                                            \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 43,630,090\n",
            "Trainable params: 1,003,530\n",
            "Non-trainable params: 42,626,560\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Эксперимент №3.**\n",
        "\n",
        "max_trials=25\n",
        "\n",
        "tuner=None\n",
        "\n",
        "В случае, когда тюнер не указывается, применяется тюнер 'greedy'\n",
        "\n",
        "'Greedy' тюнер является наиболее простым тюнером и используется по умолчанию. Он рассматривает небольшой набор моделей, начиная с наиболее простой, и последовательно увеличивает их сложность. После каждого шага тюнер выбирает лучшую модель и продолжает увеличивать ее сложность, пока не достигнет максимально заданной глубины. Это означает, что тюнеру не нужно проводить вычислительно дорогостоящие эксперименты с очень сложными моделями, что делает его очень эффективным и быстрым. Однако, в связи с этим, 'greedy' тюнер может не сходиться к глобальному оптимуму и может пропустить более сложные модели, которые могут давать лучшее качество на данных."
      ],
      "metadata": {
        "id": "eoS4-JUameuw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Обучение модели\n",
        "# Определение EarlyStopping-коллбека\n",
        "es_callback = EarlyStopping(monitor='val_loss', patience=4)\n",
        "start_time = time.time()\n",
        "clf_3 = ak.ImageClassifier(overwrite=True, max_trials=25, num_classes=10, multi_label=False, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"], \n",
        "                         project_name=\"my_project\", directory=\"my_dir\", seed=44, max_model_size=None, objective ='val_accuracy')\n",
        "# Обучаем 10  моделей\n",
        "clf_3.fit(x_train, y_train, epochs=10, batch_size=64, callbacks=[es_callback], validation_data=(x_val, y_val))\n",
        "end_time = time.time()\n",
        "# Вывод времени обучения и точности модели\n",
        "print(\"Total training time:\", end_time - start_time) \n",
        "print(\"Training accuracy:\", clf_3.evaluate(x_train, y_train)[1])\n",
        "print(\"Test accuracy:\", clf_3.evaluate(x_val, y_val)[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p3XMOXvolawr",
        "outputId": "492a43e3-5b22-4ec2-b113-0adc8c9f1635"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 25 Complete [00h 00m 15s]\n",
            "val_accuracy: 0.9933333396911621\n",
            "\n",
            "Best val_accuracy So Far: 0.9933333396911621\n",
            "Total elapsed time: 00h 48m 39s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n",
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total training time: 2927.768089532852\n",
            "90/90 [==============================] - 1s 7ms/step - loss: 0.0062 - accuracy: 1.0000\n",
            "Training accuracy: 1.0\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.0640 - accuracy: 0.9933\n",
            "Test accuracy: 0.9933333396911621\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_3 = clf_3.export_model()\n",
        "model_3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZgTLoMwm_o4",
        "outputId": "18fdafb3-fb0d-424e-bf36-e5e765c84049"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
            "                                                                 \n",
            " cast_to_float32 (CastToFloa  (None, 64, 64, 3)        0         \n",
            " t32)                                                            \n",
            "                                                                 \n",
            " normalization (Normalizatio  (None, 64, 64, 3)        7         \n",
            " n)                                                              \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 60, 60, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 30, 30, 64)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 30, 30, 64)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 57600)             0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 57600)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                576010    \n",
            "                                                                 \n",
            " classification_head_1 (Soft  (None, 10)               0         \n",
            " max)                                                            \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 595,409\n",
            "Trainable params: 595,402\n",
            "Non-trainable params: 7\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AutoKeras для бинарной классификации текстов на основе датасета IMDB (Internet Movie Database) \n",
        "\n",
        "Это база данных, в которой хранится информация о фильмах, телешоу, актерах, кинокритиках и других связанных с кино сущностях. В рамках машинного обучения датасет IMDB относится к набору данных, содержащему рецензии на фильмы. Он содержит отзывы, оставленные пользователями сайта IMDB для фильмов в жанре «экшн» и «драма». Каждый отзыв помечен как положительный или отрицательный, и используется для задач классификации текста, например, для определения тональности текста.\n",
        "\n",
        "В данном примере мы не будем указывать параметр tuner - таким образом используется настраиваемый для конкретной задачи tuner, который сначала оценивает наиболее часто используемые модели для задачи, а затем исследует другие модели."
      ],
      "metadata": {
        "id": "rn0iDOcParhl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_files\n",
        "import tensorflow as tf\n",
        "import autokeras as ak"
      ],
      "metadata": {
        "id": "ohDmZ19wAr-A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# загружаем датасет с рецензиями для бинарной классификации текстов\n",
        "dataset = tf.keras.utils.get_file(\n",
        "    fname=\"aclImdb.tar.gz\",\n",
        "    origin=\"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\",\n",
        "    extract=True,\n",
        ")\n",
        "\n",
        "# set path to dataset\n",
        "IMDB_DATADIR = os.path.join(os.path.dirname(dataset), \"aclImdb\")\n",
        "\n",
        "classes = [\"pos\", \"neg\"]\n",
        "train_data = load_files(\n",
        "    os.path.join(IMDB_DATADIR, \"train\"), shuffle=True, categories=classes\n",
        ")\n",
        "test_data = load_files(\n",
        "    os.path.join(IMDB_DATADIR, \"test\"), shuffle=False, categories=classes\n",
        ")\n",
        "\n",
        "x_train = np.array(train_data.data)\n",
        "y_train = np.array(train_data.target)\n",
        "x_test = np.array(test_data.data)\n",
        "y_test = np.array(test_data.target)\n",
        "\n",
        "print(x_train.shape)  # (25000,)\n",
        "print(y_train.shape)  # (25000, 1)\n",
        "print(x_train[0][:50])  # this film was just brilliant casting\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fGL6DUF0AsAk",
        "outputId": "37e8a7d2-ef51-48fd-861e-fe8c5fdb6658"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(25000,)\n",
            "(25000,)\n",
            "b'Zero Day leads you to think, even re-think why two'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Важный момент - исли используется \"тяжелая\" предобученная модель, например, bert, AutoKeras сам уменьшает параметр batch_size, не прерывая обучение."
      ],
      "metadata": {
        "id": "C-m50820aRc8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Запустим классификатор текстов, сделаем 5 моделей\n",
        "clf = ak.TextClassifier(\n",
        "    overwrite=True, max_trials=3, objective = 'val_accuracy'\n",
        ")  \n",
        "# Feed the text classifier with training data.\n",
        "hist=clf.fit(x_train, y_train, epochs=10, validation_data=(x_test, y_test), batch_size=64)\n",
        "# Predict with the best model.\n",
        "predicted_y = clf.predict(x_test)\n",
        "# Evaluate the best model with testing data.\n",
        "print(clf.evaluate(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rRplYEo6VaRH",
        "outputId": "8001b2d8-a3b8-4723-93f7-097da1743fa9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 3 Complete [00h 01m 18s]\n",
            "\n",
            "Best val_accuracy So Far: 0.8925600051879883\n",
            "Total elapsed time: 00h 04m 20s\n",
            "Epoch 1/6\n",
            "391/391 [==============================] - 39s 96ms/step - loss: 0.4758 - accuracy: 0.7436 - val_loss: 0.2895 - val_accuracy: 0.8788\n",
            "Epoch 2/6\n",
            "391/391 [==============================] - 9s 24ms/step - loss: 0.2526 - accuracy: 0.8991 - val_loss: 0.2675 - val_accuracy: 0.8912\n",
            "Epoch 3/6\n",
            "391/391 [==============================] - 9s 23ms/step - loss: 0.1790 - accuracy: 0.9337 - val_loss: 0.3141 - val_accuracy: 0.8808\n",
            "Epoch 4/6\n",
            "391/391 [==============================] - 9s 22ms/step - loss: 0.1292 - accuracy: 0.9537 - val_loss: 0.3830 - val_accuracy: 0.8719\n",
            "Epoch 5/6\n",
            "391/391 [==============================] - 9s 24ms/step - loss: 0.1074 - accuracy: 0.9607 - val_loss: 0.3541 - val_accuracy: 0.8897\n",
            "Epoch 6/6\n",
            "391/391 [==============================] - 9s 23ms/step - loss: 0.0835 - accuracy: 0.9695 - val_loss: 0.3910 - val_accuracy: 0.8846\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 4s 5ms/step\n",
            "782/782 [==============================] - 4s 5ms/step\n",
            "782/782 [==============================] - 6s 7ms/step - loss: 0.3910 - accuracy: 0.8846\n",
            "[0.3910045623779297, 0.8846399784088135]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Получаем лучшую модель\n",
        "mod=clf.export_model()\n",
        "mod.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZuRP8oPVaYy",
        "outputId": "dd147e94-5bf0-4241-aff4-3e0826f2917b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None,)]                 0         \n",
            "                                                                 \n",
            " expand_last_dim (ExpandLast  (None, 1)                0         \n",
            " Dim)                                                            \n",
            "                                                                 \n",
            " text_vectorization (TextVec  (None, 512)              0         \n",
            " torization)                                                     \n",
            "                                                                 \n",
            " embedding (Embedding)       (None, 512, 64)           320064    \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 512, 64)           0         \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 508, 256)          82176     \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 256)              0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               65792     \n",
            "                                                                 \n",
            " re_lu (ReLU)                (None, 256)               0         \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 256)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            " classification_head_1 (Acti  (None, 1)                0         \n",
            " vation)                                                         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 468,289\n",
            "Trainable params: 468,289\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Keras Tuner"
      ],
      "metadata": {
        "id": "-A0jUrMFC404"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keras Tuner - это библиотека, которая помогает выбрать оптимальные гиперпараметры для моделей, созданных с помощью Keras. Это позволяет автоматизировать процесс оптимизации гиперпараметров, что может существенно сократить время и усилия, затраченные на поиск лучшей модели.\n",
        "\n",
        "Keras Tuner обеспечивает удобный интерфейс для определения гиперпараметров, исследуемых во время поиска, а также для выбора стратегии поиска. Библиотека поддерживает несколько стратегий поиска гиперпараметров, включая случайный поиск, поиск по сетке и поиск по градиентам.\n",
        "\n",
        "Основные компоненты Keras Tuner:\n",
        "\n",
        "* HyperModel - класс, который определяет архитектуру модели, которую нужно настроить. Обычно он наследуется от класса keras.Model.\n",
        "* HyperParameters - класс, который определяет гиперпараметры, которые необходимо настроить. Он содержит методы для определения типов гиперпараметров, их диапазонов значений и других характеристик.\n",
        "* Tuner - класс, который определяет стратегию поиска гиперпараметров. Он принимает на вход объект HyperModel и HyperParameters, а затем настраивает гиперпараметры, используя выбранную стратегию поиска. Результатом работы Tuner является оптимальный набор гиперпараметров.\n",
        "* Oracle - класс, который определяет правила остановки поиска. Он определяет, когда поиск должен быть остановлен на основе заданных условий, таких как количество итераций или улучшение метрики.\n",
        "* Callbacks - классы обратного вызова, которые можно использовать для мониторинга и сохранения состояния поиска."
      ],
      "metadata": {
        "id": "Q42IEo0GDl4W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "kerastuner.tuners - это модуль библиотеки Keras Tuner, который содержит различные классы тюнеров для поиска оптимальных гиперпараметров моделей Keras.\n",
        "\n",
        "Тюнеры Keras Tuner позволяют оптимизировать гиперпараметры модели, выбирая наиболее перспективные варианты из заданного диапазона значений. В этом процессе тюнер автоматически обучает и оценивает модели с разными комбинациями гиперпараметров и выбирает лучшую на основе заданной метрики.\n",
        "\n",
        "Классы тюнеров в kerastuner.tuners включают в себя:\n",
        "\n",
        "- RandomSearch - ищет лучшие гиперпараметры, выбирая их случайным образом из заданного диапазона значений.\n",
        "- Hyperband - комбинация методов градиентной оптимизации и оптимизации гиперпараметров. Этот тюнер использует алгоритм Hyperband для пропуска наиболее обещающих моделей и оптимизации гиперпараметров только для них.\n",
        "- BayesianOptimization - использует байесовскую оптимизацию для поиска лучших гиперпараметров.\n",
        "- Sklearn - тюнер для моделей, совместимых со Scikit-Learn. Он использует случайный поиск или генетические алгоритмы для оптимизации гиперпараметров."
      ],
      "metadata": {
        "id": "8E02nNEhphJH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner"
      ],
      "metadata": {
        "id": "czUE9Cvf45dW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "863b289e-eb37-4746-ea10-fead306e0a2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: keras-tuner in /usr/local/lib/python3.8/dist-packages (1.3.0)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (7.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (2.25.1)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (1.0.4)\n",
            "Requirement already satisfied: tensorflow>=2.0 in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (2.11.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from keras-tuner) (23.0)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (3.19.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (57.4.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (0.4.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.4.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (23.1.21)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (4.5.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.22.4)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (15.0.6.1)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (2.11.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.51.1)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (2.11.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.14.1)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (2.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (0.30.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (2.11.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0->keras-tuner) (3.3.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (2.0.10)\n",
            "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (0.18.2)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (5.7.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (2.6.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (0.7.5)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (4.4.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython->keras-tuner) (0.2.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->keras-tuner) (4.0.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow>=2.0->keras-tuner) (0.38.4)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython->keras-tuner) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->keras-tuner) (0.2.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (1.0.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (2.16.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (0.4.6)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (5.3.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (6.0.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (3.14.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow>=2.0->keras-tuner) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from kerastuner.tuners import RandomSearch\n",
        "from kerastuner.tuners import Hyperband\n",
        "from kerastuner.engine.hyperparameters import HyperParameters\n",
        "import keras_tuner as kt"
      ],
      "metadata": {
        "id": "NgwWbkcPbi8J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a66bb3d4-efe0-4ea9-b0ca-10405e87920b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-32-d9e8d2ba1c76>:1: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
            "  from kerastuner.tuners import RandomSearch\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Определение функции для построения модели\n",
        "def model_builder(hp):\n",
        "  model = Sequential()\n",
        "  #Настраиваем параметры  у первого слоя Conv2D\n",
        "  #hp_units_dense = hp.Int('units', min_value=32, max_value=512, step=32)\n",
        "  hp_units_conv2D = hp.Int('units', min_value=32, max_value=512, step=32)\n",
        "  model.add(Conv2D(filters=hp_units_conv2D, kernel_size=3, activation='relu'))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(10))\n",
        "\n",
        "  # Настраиваем параметр learning rate для оптимайзера\n",
        "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-2, 1e-3, 1e-4])\n",
        "\n",
        "  model.compile(optimizer=Adam(learning_rate=hp_learning_rate),\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return model\n",
        "\n",
        "# Определение гиперпараметров для настройки\n",
        "tuner_search = RandomSearch(model_builder,\n",
        "                            objective='val_accuracy',\n",
        "                            max_trials=10,\n",
        "                            directory='output',\n",
        "                            project_name='drivers_keras_tuner')\n",
        "\n",
        "# Запуск настройки гиперпараметров\n",
        "tuner_search.search(x_train, y_train, epochs=10, batch_size=64,  validation_data=(x_val, y_val))\n",
        "\n",
        "# Получение наилучшей модели\n",
        "best_model = tuner_search.get_best_models(num_models=1)[0]\n",
        "\n",
        "# Оценка наилучшей модели на тестовых данных\n",
        "test_loss, test_accuracy = best_model.evaluate(x_val, y_val)\n",
        "print('Test accuracy:', test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-AQ4_bbCbi-6",
        "outputId": "254fa88f-8bb7-4b54-e607-9b01cebe382c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 03m 23s]\n",
            "val_accuracy: 0.14666666090488434\n",
            "\n",
            "Best val_accuracy So Far: 0.1599999964237213\n",
            "Total elapsed time: 00h 24m 31s\n",
            "5/5 [==============================] - 1s 221ms/step - loss: 8.7236 - accuracy: 0.1600\n",
            "Test accuracy: 0.1599999964237213\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWP8HNKgcDLQ",
        "outputId": "c8d0de9e-9076-4024-8da9-7387c4ff5492"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 62, 62, 448)       12544     \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1722112)           0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                17221130  \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17,233,674\n",
            "Trainable params: 17,233,674\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Точность получилась очень низкой. Попробуем добавить слоев в модель, изменим Tuner на Hyperband"
      ],
      "metadata": {
        "id": "m1GOZPdx43Bo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Определение функции для построения модели\n",
        "def model_builder_2(hp):\n",
        "  model = Sequential()\n",
        "  hp_units_dense = hp.Int('units', min_value=32, max_value=512, step=32)\n",
        "  # Определение количества слоев и их размерности\n",
        "  for i in range(hp.Int('num_layers', 1, 4)):\n",
        "      model.add(Conv2D(filters=hp.Int('units_' + str(i), 32, 256, 32), kernel_size= 3, activation=hp.Choice('activation_' + str(i), ['relu', 'tanh', 'sigmoid'])))\n",
        "  # Определение количества слоев и их размерности\n",
        "  for i in range(hp.Int('num_layers', 1, 4)):\n",
        "      model.add(Dense(units=hp.Int('units_' + str(i), 32, 256, 32), activation=hp.Choice('activation_' + str(i), ['relu', 'tanh', 'sigmoid'])))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(10, activation=\"softmax\"))\n",
        "  hp_learning_rate = hp.Choice('learning_rate', values=[1e-3, 1e-4])\n",
        "\n",
        "  model.compile(optimizer=Adam(learning_rate=hp_learning_rate),\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  return model\n",
        "\n",
        "# Определение гиперпараметров для настройки\n",
        "tuner_search = Hyperband(model_builder_2,\n",
        "                            objective='val_accuracy', max_epochs=15,\n",
        "                            \n",
        "                            directory='output',\n",
        "                            project_name='drivers_keras_tuner_2')\n",
        "\n",
        "# Запуск настройки гиперпараметров\n",
        "tuner_search.search(x_train, y_train, epochs=7, batch_size=64,  validation_data=(x_val, y_val))\n"
      ],
      "metadata": {
        "id": "Li7vZNMh5Ep5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af6ef79f-b823-4d1e-bed7-9707fef38ed9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 30 Complete [00h 01m 47s]\n",
            "val_accuracy: 0.9800000190734863\n",
            "\n",
            "Best val_accuracy So Far: 0.9866666793823242\n",
            "Total elapsed time: 00h 12m 56s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models = tuner_search.get_best_models(num_models=2)\n"
      ],
      "metadata": {
        "id": "6l0uNJZunfbQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a38aa519-5418-4404-ec5f-4c9dd99dc2ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-0.kernel\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-0.bias\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.kernel\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.bias\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-2.kernel\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-2.bias\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-3.kernel\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-3.bias\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-4.kernel\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-4.bias\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-5.kernel\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-5.bias\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-6.kernel\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-6.bias\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-7.kernel\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-7.bias\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-8.kernel\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-8.bias\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.iter\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_1\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer.beta_2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = tuner_search.get_best_models(num_models=1)[0]\n",
        "best_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K2dsSyxPrSvb",
        "outputId": "ec1e352e-3ced-4dd0-8d65-24f57e06c9fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.sequential.Sequential at 0x7f864ac988b0>"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Получение наилучшей модели\n",
        "best_model_2 = tuner_search.get_best_models(num_models=1)[0]\n",
        "\n",
        "# Оценка наилучшей модели на тестовых данных\n",
        "test_loss, test_accuracy_2 = best_model_2.evaluate(x_val, y_val)\n",
        "print('Test accuracy:', test_accuracy_2)"
      ],
      "metadata": {
        "id": "H52CBG6ihm3-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64f8b1f7-845a-42f0-8d33-50c2347dbcd8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 1s 11ms/step - loss: 0.0667 - accuracy: 0.9867\n",
            "Test accuracy: 0.9866666793823242\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_2.summary()"
      ],
      "metadata": {
        "id": "p99xoS5aFeUs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a845143d-7d79-4c7c-f468-7e065d4aca5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 62, 62, 64)        1792      \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 60, 60, 32)        18464     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 60, 60, 64)        2112      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 60, 60, 32)        2080      \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 115200)            0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                1152010   \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,176,458\n",
            "Trainable params: 1,176,458\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "KerasTuner включает несколько подклассов, называемых \"tuners\", которые определяют, какую стратегию использовать при поиске наилучших гиперпараметров. Некоторые из наиболее популярных тюнеров в KerasTuner включают GridSearch, RandomSearch и Hyperband.\n",
        "\n",
        "RandomSearch выбирает случайную комбинацию гиперпараметров и проверяет ее. Hyperband - более эффективный тюнер, который использует несколько итераций и удаляет слабые модели, чтобы сосредоточиться на перспективных кандидатах.\n",
        "Есть еще BayesianOptimization Tuner, Sklearn Tuner, The base Tuner class\n",
        "\n",
        "После того как тюнер завершит процесс подбора наилучших гиперпараметров, он возвращает модель Keras, которая может быть использована для обучения на данных."
      ],
      "metadata": {
        "id": "5zazwFWMUH4T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Keras Tuner для бинарной классификации текстов**"
      ],
      "metadata": {
        "id": "fmpRPDjXFF_K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "from kerastuner.tuners import RandomSearch\n",
        "from kerastuner.engine.hyperparameters import HyperParameters\n",
        "\n",
        "# Загрузка данных\n",
        "data = keras.datasets.imdb\n",
        "(train_data, train_labels), (test_data, test_labels) = data.load_data(num_words=10000)\n",
        "\n",
        "# Преобразование данных\n",
        "train_data = keras.preprocessing.sequence.pad_sequences(train_data, value=0, padding='post', maxlen=256)\n",
        "test_data = keras.preprocessing.sequence.pad_sequences(test_data, value=0, padding='post', maxlen=256)\n",
        "\n",
        "# Определение функции для построения модели\n",
        "def build_model(hp):\n",
        "    model = keras.Sequential()\n",
        "    # Добавление слоев эмбеддинга\n",
        "    model.add(layers.Embedding(input_dim=10000, output_dim=hp.Int('embedding_dim', min_value=32, max_value=256, step=32)))\n",
        "    model.add(layers.GlobalAveragePooling1D())\n",
        "    # Определение количества слоев и их размерности\n",
        "    for i in range(hp.Int('num_layers', 1, 4)):\n",
        "        model.add(layers.Dense(units=hp.Int('units_' + str(i), 32, 256, 32), activation=hp.Choice('activation_' + str(i), ['relu', 'tanh', 'sigmoid'])))\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "    # Определение оптимизатора и скомпилирование модели\n",
        "    model.compile(optimizer=keras.optimizers.Adam(hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\n",
        "                  loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Определение гиперпараметров для настройки\n",
        "tuner_search = RandomSearch(build_model,\n",
        "                            objective='val_accuracy',\n",
        "                            max_trials=5,\n",
        "                            directory='output',\n",
        "                            project_name='imdb_sentiment_analysis')\n",
        "\n",
        "# Запуск настройки гиперпараметров\n",
        "tuner_search.search(train_data, train_labels, epochs=5, validation_split=0.2)\n",
        "\n",
        "# Получение наилучшей модели\n",
        "best_model = tuner_search.get_best_models(num_models=1)[0]\n",
        "\n",
        "# Оценка наилучшей модели на тестовых данных\n",
        "test_loss, test_accuracy = best_model.evaluate(test_data, test_labels)\n",
        "print('Test accuracy:', test_accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yhZOFrNHAsH6",
        "outputId": "9a00fe73-64e6-4ea1-ff12-f5f9b651b560"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 5 Complete [00h 01m 37s]\n",
            "val_accuracy: 0.8866000175476074\n",
            "\n",
            "Best val_accuracy So Far: 0.8913999795913696\n",
            "Total elapsed time: 00h 09m 55s\n",
            "782/782 [==============================] - 3s 4ms/step - loss: 0.2996 - accuracy: 0.8806\n",
            "Test accuracy: 0.8805999755859375\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Получение наилучшей модели\n",
        "best_model_3 = tuner_search.get_best_models(num_models=1)[0]"
      ],
      "metadata": {
        "id": "R4_aP_xwufja"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_3.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khQJMOvdufmG",
        "outputId": "44affcdc-4b1a-4b64-d5fc-00f7a48a8f72"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, None, 192)         1920000   \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 192)              0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               24704     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                4128      \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 128)               4224      \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,953,185\n",
            "Trainable params: 1,953,185\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Функция build_model определяет архитектуру модели с помощью Keras Tuner. Она принимает объект HyperParameters, который содержит гиперпараметры, которые мы хотим оптимизировать. В этом примере мы оптимизируем гиперпараметры, связанные с размерностью векторного пространства эмбеддингов, количеством слоев и их размерностью, функциями активации и скоростью обучения.\n",
        "\n",
        "Мы используем класс RandomSearch из Keras Tuner для настройки гиперпараметров. Метод search запускает процесс настройки, в котором модели обучаются на обучающем наборе данных и проверяются на валидационном наборе данных для оценки их производительности. Мы указываем максимальное количество испытаний (max_trials), которые хотим выполнить, а также папку directory и имя проекта project_name, в которых будут храниться результаты настройки.\n",
        "\n",
        "После того, как настройка завершена, мы получаем наилучшую модель с помощью метода get_best_models. Затем мы оцениваем производительность этой модели на тестовом наборе данных с помощью метода evaluate.\n",
        "\n"
      ],
      "metadata": {
        "id": "7zt8rCo341DI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Talos"
      ],
      "metadata": {
        "id": "1sj68Fhc53q5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Talos - это библиотека для автоматической настройки гиперпараметров моделей глубокого обучения. Talos основана на библиотеке Keras и предоставляет простой и удобный API для оптимизации гиперпараметров.\n",
        "\n",
        "С помощью Talos вы можете оптимизировать различные гиперпараметры, такие как размер батча, скорость обучения, количество слоев и их размерность, функции активации, параметры регуляризации и многое другое. Talos использует методы оптимизации, такие как Grid Search, Random Search, Fmin и другие, чтобы найти наилучшую комбинацию гиперпараметров.\n",
        "\n",
        "Основной функциональностью Talos является Scan(), которая запускает процесс поиска оптимальных гиперпараметров. Она принимает на вход модель, гиперпараметры, настройки оптимизации и данные для обучения. После этого она запускает обучение и проверку модели с различными комбинациями гиперпараметров и сохраняет результаты."
      ],
      "metadata": {
        "id": "i6yOlHEU57Er"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install talos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mojJO6NY71tp",
        "outputId": "09fd72ad-2038-4c01-98d2-e1d30c00a6e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting talos\n",
            "  Downloading talos-1.3-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.4/56.4 KB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kerasplotlib\n",
            "  Downloading kerasplotlib-1.0-py3-none-any.whl (4.3 kB)\n",
            "Collecting wrangle\n",
            "  Downloading wrangle-0.7.2-py3-none-any.whl (52 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.3/52.3 KB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sklearn\n",
            "  Downloading sklearn-0.0.post1.tar.gz (3.6 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting astetik\n",
            "  Downloading astetik-1.13-py3-none-any.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m99.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from talos) (2.25.1)\n",
            "Collecting chances\n",
            "  Downloading chances-0.1.9.tar.gz (35 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: statsmodels>=0.11.0 in /usr/local/lib/python3.8/dist-packages (from talos) (0.12.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from talos) (4.64.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from talos) (1.3.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from talos) (1.21.6)\n",
            "Requirement already satisfied: tensorflow>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from talos) (2.11.0)\n",
            "Requirement already satisfied: patsy>=0.5 in /usr/local/lib/python3.8/dist-packages (from statsmodels>=0.11.0->talos) (0.5.3)\n",
            "Requirement already satisfied: scipy>=1.1 in /usr/local/lib/python3.8/dist-packages (from statsmodels>=0.11.0->talos) (1.7.3)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->talos) (2022.7.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->talos) (2.8.2)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0.0->talos) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0.0->talos) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0.0->talos) (0.30.0)\n",
            "Requirement already satisfied: keras<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0.0->talos) (2.11.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0.0->talos) (23.1.21)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0.0->talos) (3.19.6)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0.0->talos) (2.2.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0.0->talos) (1.15.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0.0->talos) (1.6.3)\n",
            "Requirement already satisfied: tensorboard<2.12,>=2.11 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0.0->talos) (2.11.2)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0.0->talos) (3.1.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0.0->talos) (1.4.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0.0->talos) (15.0.6.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0.0->talos) (23.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0.0->talos) (4.5.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0.0->talos) (1.51.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0.0->talos) (57.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0.0->talos) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.12,>=2.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0.0->talos) (2.11.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow>=2.0.0->talos) (1.14.1)\n",
            "Collecting geonamescache\n",
            "  Downloading geonamescache-1.5.0-py3-none-any.whl (26.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.4/26.4 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: seaborn in /usr/local/lib/python3.8/dist-packages (from astetik->talos) (0.11.2)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.8/dist-packages (from astetik->talos) (7.9.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.8/dist-packages (from kerasplotlib->talos) (3.2.2)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->talos) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->talos) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->talos) (2.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests->talos) (1.24.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow>=2.0.0->talos) (0.38.4)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0.0->talos) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0.0->talos) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0.0->talos) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0.0->talos) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0.0->talos) (3.4.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow>=2.0.0->talos) (2.16.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from IPython->astetik->talos) (2.0.10)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from IPython->astetik->talos) (0.7.5)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from IPython->astetik->talos) (0.2.0)\n",
            "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.8/dist-packages (from IPython->astetik->talos) (0.18.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from IPython->astetik->talos) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from IPython->astetik->talos) (4.4.2)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from IPython->astetik->talos) (5.7.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from IPython->astetik->talos) (4.8.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.8/dist-packages (from matplotlib->kerasplotlib->talos) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->kerasplotlib->talos) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from matplotlib->kerasplotlib->talos) (1.4.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.0.0->talos) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.0.0->talos) (4.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.0.0->talos) (5.3.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow>=2.0.0->talos) (1.3.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->IPython->astetik->talos) (0.8.3)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow>=2.0.0->talos) (6.0.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->IPython->astetik->talos) (0.2.6)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->IPython->astetik->talos) (0.7.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow>=2.0.0->talos) (3.13.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow>=2.0.0->talos) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow>=2.0.0->talos) (3.2.2)\n",
            "Building wheels for collected packages: chances, sklearn\n",
            "  Building wheel for chances (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for chances: filename=chances-0.1.9-py3-none-any.whl size=41609 sha256=e075b4aa67615cc9ecc94e3cdd19326e35be9d4c73a352d2ad3c3e58a9abc0d7\n",
            "  Stored in directory: /root/.cache/pip/wheels/bc/47/dc/208d4038848287f804b6ededf43632ba7dbea530fdb3a069e4\n",
            "  Building wheel for sklearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sklearn: filename=sklearn-0.0.post1-py3-none-any.whl size=2344 sha256=637bd802b7ac238b941381c59927d7275f9706906a911a22971c34d294517758\n",
            "  Stored in directory: /root/.cache/pip/wheels/14/25/f7/1cc0956978ae479e75140219088deb7a36f60459df242b1a72\n",
            "Successfully built chances sklearn\n",
            "Installing collected packages: sklearn, geonamescache, chances, kerasplotlib, wrangle, astetik, talos\n",
            "Successfully installed astetik-1.13 chances-0.1.9 geonamescache-1.5.0 kerasplotlib-1.0 sklearn-0.0.post1 talos-1.3 wrangle-0.7.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import talos as ta\n",
        "from talos.model.normalizers import lr_normalizer\n",
        "from talos import Scan\n",
        "#from talos.utils import dataset"
      ],
      "metadata": {
        "id": "m8T8tDKm72_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Определяем модель\n",
        "def talos_model(x_train, y_train, x_val, y_val, params):\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(params['filters'], kernel_size=3, activation=params['activation'], input_shape=(64, 64, 3)))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Conv2D(params['filters'], kernel_size=3, activation=params['activation']))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(params['hidden_units'], activation=params['activation']))\n",
        "    model.add(Dropout(params['dropout']))\n",
        "    model.add(Dense(10, activation='softmax'))\n",
        "\n",
        "    # Компилируем модель\n",
        "    model.compile(loss='categorical_crossentropy', optimizer=Adam(lr=params['learning_rate']), metrics=['accuracy'])\n",
        "\n",
        "    # Обучаем модель\n",
        "    history = model.fit(x_train, y_train,\n",
        "                        validation_data=(x_val, y_val),\n",
        "                        batch_size=params['batch_size'],\n",
        "                        epochs=10,\n",
        "                        verbose=0)\n",
        "    return history, model\n",
        "\n",
        "# Определяем гиперпараметры\n",
        "p = {'filters': [16, 32],\n",
        "     #'kernel_size': [(3, 3), (5, 5)],\n",
        "     'hidden_units': [32, 64],\n",
        "     'dropout': [0.2, 0.3],\n",
        "     'batch_size': [32, 64],\n",
        "     #'epochs': [5, 10],\n",
        "     'activation': ['relu', 'elu'],\n",
        "     'learning_rate': [0.001, 0.0001]}\n",
        "\n",
        "# Запускаем оптимизацию гиперпараметров\n",
        "scan_object = ta.Scan(x=x_train,\n",
        "                      y=y_train,\n",
        "                      x_val=x_val,\n",
        "                      y_val=y_val,\n",
        "                      model=talos_model,\n",
        "                      params=p,\n",
        "                      experiment_name='talos_mod')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwZEd5ZP73Jr",
        "outputId": "8e5e76f0-29d9-4246-adf6-71c45d823141"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 64/64 [05:58<00:00,  5.60s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# получаем отчет о результатах сканирования\n",
        "r = ta.Reporting(scan_object)\n",
        "\n",
        "# выводим лучшие параметры\n",
        "print(r.best_params)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Doxwipm25Op",
        "outputId": "425178e2-8ba2-43a5-a6f8-93451856fcc7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<bound method Analyze.best_params of <talos.commands.analyze.Analyze object at 0x7f417cda3ac0>>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r.data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "TBKtpMO39Zdh",
        "outputId": "e05d1a8d-cedc-462d-c65a-0550794006ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              start              end  duration  round_epochs      loss  \\\n",
              "0   02/21/23-164042  02/21/23-164048  6.490367            10  0.314440   \n",
              "1   02/21/23-164049  02/21/23-164054  5.077243            10  1.361121   \n",
              "2   02/21/23-164054  02/21/23-164059  5.304686            10  0.057808   \n",
              "3   02/21/23-164059  02/21/23-164104  4.714167            10  1.103133   \n",
              "4   02/21/23-164104  02/21/23-164109  4.359731            10  0.253756   \n",
              "..              ...              ...       ...           ...       ...   \n",
              "59  02/21/23-164612  02/21/23-164618  6.012555            10  0.565079   \n",
              "60  02/21/23-164618  02/21/23-164624  5.991820            10  0.282046   \n",
              "61  02/21/23-164624  02/21/23-164630  5.990026            10  1.357684   \n",
              "62  02/21/23-164631  02/21/23-164635  4.367067            10  0.031867   \n",
              "63  02/21/23-164635  02/21/23-164640  4.482332            10  0.775053   \n",
              "\n",
              "    accuracy  val_loss  val_accuracy  filters  hidden_units  dropout  \\\n",
              "0   0.895088  0.218712      0.933333       16            32      0.2   \n",
              "1   0.556842  1.200270      0.640000       16            32      0.2   \n",
              "2   0.983509  0.126981      0.966667       16            32      0.2   \n",
              "3   0.682807  1.052074      0.666667       16            32      0.2   \n",
              "4   0.916140  0.180692      0.926667       16            32      0.2   \n",
              "..       ...       ...           ...      ...           ...      ...   \n",
              "59  0.855088  0.508742      0.886667       32            64      0.3   \n",
              "60  0.908772  0.164445      0.940000       32            64      0.3   \n",
              "61  0.546316  1.225586      0.620000       32            64      0.3   \n",
              "62  0.994035  0.067176      0.973333       32            64      0.3   \n",
              "63  0.790526  0.733601      0.806667       32            64      0.3   \n",
              "\n",
              "    batch_size activation  learning_rate  \n",
              "0           32       relu         0.0010  \n",
              "1           32       relu         0.0001  \n",
              "2           32        elu         0.0010  \n",
              "3           32        elu         0.0001  \n",
              "4           64       relu         0.0010  \n",
              "..         ...        ...            ...  \n",
              "59          32        elu         0.0001  \n",
              "60          64       relu         0.0010  \n",
              "61          64       relu         0.0001  \n",
              "62          64        elu         0.0010  \n",
              "63          64        elu         0.0001  \n",
              "\n",
              "[64 rows x 14 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7265b579-226b-4220-b1f4-da1bde480761\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>duration</th>\n",
              "      <th>round_epochs</th>\n",
              "      <th>loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_accuracy</th>\n",
              "      <th>filters</th>\n",
              "      <th>hidden_units</th>\n",
              "      <th>dropout</th>\n",
              "      <th>batch_size</th>\n",
              "      <th>activation</th>\n",
              "      <th>learning_rate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>02/21/23-164042</td>\n",
              "      <td>02/21/23-164048</td>\n",
              "      <td>6.490367</td>\n",
              "      <td>10</td>\n",
              "      <td>0.314440</td>\n",
              "      <td>0.895088</td>\n",
              "      <td>0.218712</td>\n",
              "      <td>0.933333</td>\n",
              "      <td>16</td>\n",
              "      <td>32</td>\n",
              "      <td>0.2</td>\n",
              "      <td>32</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.0010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>02/21/23-164049</td>\n",
              "      <td>02/21/23-164054</td>\n",
              "      <td>5.077243</td>\n",
              "      <td>10</td>\n",
              "      <td>1.361121</td>\n",
              "      <td>0.556842</td>\n",
              "      <td>1.200270</td>\n",
              "      <td>0.640000</td>\n",
              "      <td>16</td>\n",
              "      <td>32</td>\n",
              "      <td>0.2</td>\n",
              "      <td>32</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.0001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>02/21/23-164054</td>\n",
              "      <td>02/21/23-164059</td>\n",
              "      <td>5.304686</td>\n",
              "      <td>10</td>\n",
              "      <td>0.057808</td>\n",
              "      <td>0.983509</td>\n",
              "      <td>0.126981</td>\n",
              "      <td>0.966667</td>\n",
              "      <td>16</td>\n",
              "      <td>32</td>\n",
              "      <td>0.2</td>\n",
              "      <td>32</td>\n",
              "      <td>elu</td>\n",
              "      <td>0.0010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>02/21/23-164059</td>\n",
              "      <td>02/21/23-164104</td>\n",
              "      <td>4.714167</td>\n",
              "      <td>10</td>\n",
              "      <td>1.103133</td>\n",
              "      <td>0.682807</td>\n",
              "      <td>1.052074</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>16</td>\n",
              "      <td>32</td>\n",
              "      <td>0.2</td>\n",
              "      <td>32</td>\n",
              "      <td>elu</td>\n",
              "      <td>0.0001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>02/21/23-164104</td>\n",
              "      <td>02/21/23-164109</td>\n",
              "      <td>4.359731</td>\n",
              "      <td>10</td>\n",
              "      <td>0.253756</td>\n",
              "      <td>0.916140</td>\n",
              "      <td>0.180692</td>\n",
              "      <td>0.926667</td>\n",
              "      <td>16</td>\n",
              "      <td>32</td>\n",
              "      <td>0.2</td>\n",
              "      <td>64</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.0010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>02/21/23-164612</td>\n",
              "      <td>02/21/23-164618</td>\n",
              "      <td>6.012555</td>\n",
              "      <td>10</td>\n",
              "      <td>0.565079</td>\n",
              "      <td>0.855088</td>\n",
              "      <td>0.508742</td>\n",
              "      <td>0.886667</td>\n",
              "      <td>32</td>\n",
              "      <td>64</td>\n",
              "      <td>0.3</td>\n",
              "      <td>32</td>\n",
              "      <td>elu</td>\n",
              "      <td>0.0001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>02/21/23-164618</td>\n",
              "      <td>02/21/23-164624</td>\n",
              "      <td>5.991820</td>\n",
              "      <td>10</td>\n",
              "      <td>0.282046</td>\n",
              "      <td>0.908772</td>\n",
              "      <td>0.164445</td>\n",
              "      <td>0.940000</td>\n",
              "      <td>32</td>\n",
              "      <td>64</td>\n",
              "      <td>0.3</td>\n",
              "      <td>64</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.0010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>02/21/23-164624</td>\n",
              "      <td>02/21/23-164630</td>\n",
              "      <td>5.990026</td>\n",
              "      <td>10</td>\n",
              "      <td>1.357684</td>\n",
              "      <td>0.546316</td>\n",
              "      <td>1.225586</td>\n",
              "      <td>0.620000</td>\n",
              "      <td>32</td>\n",
              "      <td>64</td>\n",
              "      <td>0.3</td>\n",
              "      <td>64</td>\n",
              "      <td>relu</td>\n",
              "      <td>0.0001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>02/21/23-164631</td>\n",
              "      <td>02/21/23-164635</td>\n",
              "      <td>4.367067</td>\n",
              "      <td>10</td>\n",
              "      <td>0.031867</td>\n",
              "      <td>0.994035</td>\n",
              "      <td>0.067176</td>\n",
              "      <td>0.973333</td>\n",
              "      <td>32</td>\n",
              "      <td>64</td>\n",
              "      <td>0.3</td>\n",
              "      <td>64</td>\n",
              "      <td>elu</td>\n",
              "      <td>0.0010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>02/21/23-164635</td>\n",
              "      <td>02/21/23-164640</td>\n",
              "      <td>4.482332</td>\n",
              "      <td>10</td>\n",
              "      <td>0.775053</td>\n",
              "      <td>0.790526</td>\n",
              "      <td>0.733601</td>\n",
              "      <td>0.806667</td>\n",
              "      <td>32</td>\n",
              "      <td>64</td>\n",
              "      <td>0.3</td>\n",
              "      <td>64</td>\n",
              "      <td>elu</td>\n",
              "      <td>0.0001</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>64 rows × 14 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7265b579-226b-4220-b1f4-da1bde480761')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7265b579-226b-4220-b1f4-da1bde480761 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7265b579-226b-4220-b1f4-da1bde480761');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_params = r.best_params(metric='val_accuracy', exclude=['param1', 'param2'])"
      ],
      "metadata": {
        "id": "Ixtyp2RS-euE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_params"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nNvs4M7q-5HT",
        "outputId": "865d6acb-659b-451e-c34c-8519d8d6f477"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[32, 'elu', '02/21/23-164434', 0.07079509645700455, 0.3, 10,\n",
              "        5.829704999923706, 32, 0.9845613837242126, 32,\n",
              "        0.05771593749523163, 0.001, '02/21/23-164440', 0],\n",
              "       [64, 'elu', '02/21/23-164631', 0.06717603653669357, 0.3, 10,\n",
              "        4.367067098617554, 32, 0.9940350651741028, 64,\n",
              "        0.031866975128650665, 0.001, '02/21/23-164635', 1],\n",
              "       [32, 'elu', '02/21/23-164303', 0.09059999138116837, 0.3, 10,\n",
              "        4.776015281677246, 16, 0.9933333396911621, 64,\n",
              "        0.03410322219133377, 0.001, '02/21/23-164307', 2],\n",
              "       [32, 'elu', '02/21/23-164519', 0.1406450718641281, 0.2, 10,\n",
              "        5.997753858566284, 32, 0.9891228079795837, 64,\n",
              "        0.03539183735847473, 0.001, '02/21/23-164525', 3],\n",
              "       [32, 'elu', '02/21/23-164054', 0.1269809454679489, 0.2, 10,\n",
              "        5.304685592651367, 16, 0.9835087656974792, 32,\n",
              "        0.05780809000134468, 0.001, '02/21/23-164059', 4],\n",
              "       [64, 'elu', '02/21/23-164158', 0.10445954650640488, 0.3, 10,\n",
              "        3.566908121109009, 16, 0.9785965085029602, 32,\n",
              "        0.08742579072713852, 0.001, '02/21/23-164202', 5],\n",
              "       [64, 'elu', '02/21/23-164542', 0.08134527504444122, 0.2, 10,\n",
              "        5.9686973094940186, 32, 0.9978947639465332, 64,\n",
              "        0.020167050883173943, 0.001, '02/21/23-164548', 6],\n",
              "       [32, 'elu', '02/21/23-164218', 0.10179471224546432, 0.2, 10,\n",
              "        6.193435430526733, 16, 0.995087742805481, 64,\n",
              "        0.025153672322630882, 0.001, '02/21/23-164225', 7],\n",
              "       [32, 'relu', '02/21/23-164508', 0.12123976647853851, 0.2, 10,\n",
              "        4.893182039260864, 32, 0.9708771705627441, 64,\n",
              "        0.08151411265134811, 0.001, '02/21/23-164513', 8],\n",
              "       [64, 'elu', '02/21/23-164457', 0.1105370819568634, 0.3, 10,\n",
              "        5.9793548583984375, 32, 0.9785965085029602, 32,\n",
              "        0.08200100809335709, 0.001, '02/21/23-164503', 9]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Auto-sklearn"
      ],
      "metadata": {
        "id": "pjq5hGw32MWE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Auto-sklearn - это библиотека автоматического машинного обучения на основе фреймворка scikit-learn. Она использует методики обучения на основе градиентного спуска и генетические алгоритмы для автоматического поиска лучших параметров модели. Auto-sklearn поддерживает как задачи классификации, так и задачи регрессии. Эта библиотека позволяет автоматически настраивать гиперпараметры и выбирать алгоритмы машинного обучения для данной задачи, что упрощает процесс обучения моделей и повышает их качество.\n",
        "\n",
        "AutoSklearnClassifier является классификатором, основанным на автоматическом машинном обучении. Он использует методы оптимизации для автоматического подбора модели и гиперпараметров на основе заданной метрики качества.\n",
        "\n",
        "Некоторые из важных параметров AutoSklearnClassifier:\n",
        "\n",
        "- time_left_for_this_task: (int, default=3600) - ограничение времени, выделенное для автоматического поиска лучшей модели. Значение указывается в секундах.\n",
        "- per_run_time_limit: (int, default=360) - максимальное время работы для одного вызова модели, выраженное в секундах.\n",
        "- memory_limit: (int, default=3072) - ограничение памяти, которую может использовать модель в мегабайтах.\n",
        "- ensemble_size: (int, default=50) - количество лучших моделей, выбранных для ансамблирования.\n",
        "- resampling_strategy: (str, default='holdout') - стратегия для оценки качества моделей. Допустимые значения - holdout, cv, cv-10, cv-5x2, subsample, subsample-iterative-fit.\n",
        "- metric: (str, default='accuracy') - метрика, используемая для оценки качества моделей. Допустимые значения - accuracy, balanced_accuracy, f1, roc_auc, precision, recall, log_loss.\n",
        "- n_jobs: (int, default=1) - количество параллельных процессов для обучения моделей."
      ],
      "metadata": {
        "id": "g2ruNhL0I9xp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install auto-sklearn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKmiYYiqLKi-",
        "outputId": "430f87af-2c18-4d96-86ea-093a51839c0b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting auto-sklearn\n",
            "  Downloading auto-sklearn-0.15.0.tar.gz (6.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.8/dist-packages (from auto-sklearn) (6.0)\n",
            "Requirement already satisfied: distributed>=2012.12 in /usr/local/lib/python3.8/dist-packages (from auto-sklearn) (2022.2.1)\n",
            "Requirement already satisfied: dask>=2021.12 in /usr/local/lib/python3.8/dist-packages (from auto-sklearn) (2022.2.1)\n",
            "Collecting liac-arff\n",
            "  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.8/dist-packages (from auto-sklearn) (3.1.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from auto-sklearn) (57.4.0)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.8/dist-packages (from auto-sklearn) (1.7.3)\n",
            "Collecting pynisher<0.7,>=0.6.3\n",
            "  Downloading pynisher-0.6.4.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ConfigSpace<0.5,>=0.4.21\n",
            "  Downloading ConfigSpace-0.4.21-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m109.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting smac<1.3,>=1.2\n",
            "  Downloading smac-1.2.tar.gz (260 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m260.9/260.9 KB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas>=1.0 in /usr/local/lib/python3.8/dist-packages (from auto-sklearn) (1.3.5)\n",
            "Collecting distro\n",
            "  Downloading distro-1.8.0-py3-none-any.whl (20 kB)\n",
            "Collecting scikit-learn<0.25.0,>=0.24.0\n",
            "  Downloading scikit_learn-0.24.2-cp38-cp38-manylinux2010_x86_64.whl (24.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.9/24.9 MB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyrfr<0.9,>=0.8.1\n",
            "  Downloading pyrfr-0.8.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.4/4.4 MB\u001b[0m \u001b[31m89.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from auto-sklearn) (4.5.0)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from auto-sklearn) (1.22.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.8/dist-packages (from auto-sklearn) (1.2.0)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.8/dist-packages (from ConfigSpace<0.5,>=0.4.21->auto-sklearn) (3.0.9)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.8/dist-packages (from ConfigSpace<0.5,>=0.4.21->auto-sklearn) (0.29.33)\n",
            "Requirement already satisfied: toolz>=0.8.2 in /usr/local/lib/python3.8/dist-packages (from dask>=2021.12->auto-sklearn) (0.12.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from dask>=2021.12->auto-sklearn) (23.0)\n",
            "Requirement already satisfied: fsspec>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from dask>=2021.12->auto-sklearn) (2023.1.0)\n",
            "Requirement already satisfied: cloudpickle>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from dask>=2021.12->auto-sklearn) (2.2.1)\n",
            "Requirement already satisfied: partd>=0.3.10 in /usr/local/lib/python3.8/dist-packages (from dask>=2021.12->auto-sklearn) (1.3.0)\n",
            "Requirement already satisfied: sortedcontainers!=2.0.0,!=2.0.1 in /usr/local/lib/python3.8/dist-packages (from distributed>=2012.12->auto-sklearn) (2.4.0)\n",
            "Requirement already satisfied: msgpack>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2012.12->auto-sklearn) (1.0.4)\n",
            "Requirement already satisfied: psutil>=5.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2012.12->auto-sklearn) (5.4.8)\n",
            "Requirement already satisfied: click>=6.6 in /usr/local/lib/python3.8/dist-packages (from distributed>=2012.12->auto-sklearn) (7.1.2)\n",
            "Requirement already satisfied: tornado>=6.0.3 in /usr/local/lib/python3.8/dist-packages (from distributed>=2012.12->auto-sklearn) (6.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.8/dist-packages (from distributed>=2012.12->auto-sklearn) (2.11.3)\n",
            "Requirement already satisfied: zict>=0.1.3 in /usr/local/lib/python3.8/dist-packages (from distributed>=2012.12->auto-sklearn) (2.2.0)\n",
            "Requirement already satisfied: tblib>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from distributed>=2012.12->auto-sklearn) (1.7.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0->auto-sklearn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.0->auto-sklearn) (2022.7.1)\n",
            "Collecting emcee>=3.0.0\n",
            "  Downloading emcee-3.1.4-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.2/46.2 KB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: locket in /usr/local/lib/python3.8/dist-packages (from partd>=0.3.10->dask>=2021.12->auto-sklearn) (1.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas>=1.0->auto-sklearn) (1.15.0)\n",
            "Requirement already satisfied: heapdict in /usr/local/lib/python3.8/dist-packages (from zict>=0.1.3->distributed>=2012.12->auto-sklearn) (1.0.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.8/dist-packages (from jinja2->distributed>=2012.12->auto-sklearn) (2.0.1)\n",
            "Building wheels for collected packages: auto-sklearn, pynisher, smac, liac-arff\n",
            "  Building wheel for auto-sklearn (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for auto-sklearn: filename=auto_sklearn-0.15.0-py3-none-any.whl size=6641945 sha256=d07638e59cabcc606e44b27f3cb5e638c4c5d746928c6a2bcd422074bced2b64\n",
            "  Stored in directory: /root/.cache/pip/wheels/c5/11/0e/aeac2cee929fa4388e528737b49deb2eea05486e6f80d61c1a\n",
            "  Building wheel for pynisher (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynisher: filename=pynisher-0.6.4-py3-none-any.whl size=7044 sha256=68679609a2b25ccb285bc6275bc3b29960e5919cf8cd2e0987a9fe1722f1a88f\n",
            "  Stored in directory: /root/.cache/pip/wheels/a7/0b/c3/169e35bcd72f20d0d5e24c37dd2dff8282cc16c06df9762ff5\n",
            "  Building wheel for smac (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for smac: filename=smac-1.2-py3-none-any.whl size=215933 sha256=15a8235ea8477989775b6cde32905d7b49e21b497033c07dba79228f7b859f02\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/0d/63/29515e546f52561bf5ff41e3968fe2c35afe4ae366be54b2c4\n",
            "  Building wheel for liac-arff (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11732 sha256=f1e27450e3d464bc862276d5b1787862e61d9ba180cd997d2e2d25df965c83b7\n",
            "  Stored in directory: /root/.cache/pip/wheels/a2/de/68/bf3972de3ecb31e32bef59a7f4c75f0687a3674c476b347c14\n",
            "Successfully built auto-sklearn pynisher smac liac-arff\n",
            "Installing collected packages: pyrfr, pynisher, liac-arff, emcee, distro, scikit-learn, ConfigSpace, smac, auto-sklearn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.2\n",
            "    Uninstalling scikit-learn-1.0.2:\n",
            "      Successfully uninstalled scikit-learn-1.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "yellowbrick 1.5 requires scikit-learn>=1.0.0, but you have scikit-learn 0.24.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed ConfigSpace-0.4.21 auto-sklearn-0.15.0 distro-1.8.0 emcee-3.1.4 liac-arff-2.5.0 pynisher-0.6.4 pyrfr-0.8.3 scikit-learn-0.24.2 smac-1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Пример использования библиотеки auto-sklearn на основе табличных данных (датасет breast_cancer)**"
      ],
      "metadata": {
        "id": "2c-N65zaN50D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pprint import pprint\n",
        "import sklearn.datasets\n",
        "import sklearn.metrics\n",
        "import sklearn.model_selection\n"
      ],
      "metadata": {
        "id": "ulschVriI9_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, y = sklearn.datasets.load_breast_cancer(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(\n",
        "    X, y, random_state=1\n",
        ")"
      ],
      "metadata": {
        "id": "vjclbrOHbbCT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import autosklearn\n",
        "from autosklearn import classification\n",
        "cls = autosklearn.classification.AutoSklearnClassifier(\n",
        "    time_left_for_this_task=120,\n",
        "    per_run_time_limit=30,\n",
        "    tmp_folder='/tmp/autosklearn_classification_example_tmp' \n",
        ")"
      ],
      "metadata": {
        "id": "01QIIKWUeBvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cls.fit(X_train, y_train, dataset_name=\"breast_cancer\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdO-IeBjbbGj",
        "outputId": "1ba15d3a-d97a-4e64-bfef-0ec8c0ab2c60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AutoSklearnClassifier(ensemble_class=<class 'autosklearn.ensembles.ensemble_selection.EnsembleSelection'>,\n",
              "                      per_run_time_limit=30, time_left_for_this_task=120,\n",
              "                      tmp_folder='/tmp/autosklearn_classification_example_tmp')"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(cls.leaderboard())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kme9pxbVbbJA",
        "outputId": "4eea31b8-d5ec-41a1-b6ed-d1aa0e05e84b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          rank  ensemble_weight               type      cost  duration\n",
            "model_id                                                              \n",
            "7            2             0.10        extra_trees  0.014184  1.937602\n",
            "27           1             0.10        extra_trees  0.014184  2.812684\n",
            "16           4             0.10  gradient_boosting  0.021277  1.329778\n",
            "21           3             0.04        extra_trees  0.021277  1.874241\n",
            "2            5             0.04      random_forest  0.028369  2.195254\n",
            "3           13             0.12                mlp  0.028369  1.327508\n",
            "10          12             0.02      random_forest  0.028369  2.677490\n",
            "11          11             0.02      random_forest  0.028369  3.557857\n",
            "13           9             0.02  gradient_boosting  0.028369  1.792805\n",
            "14          10             0.02                mlp  0.028369  2.617734\n",
            "19           8             0.04        extra_trees  0.028369  4.960261\n",
            "22           7             0.12  gradient_boosting  0.028369  1.425581\n",
            "26           6             0.02        extra_trees  0.028369  3.103458\n",
            "5           16             0.04      random_forest  0.035461  3.189750\n",
            "8           15             0.02      random_forest  0.035461  2.517287\n",
            "12          17             0.02  gradient_boosting  0.035461  1.619924\n",
            "17          14             0.02  gradient_boosting  0.035461  2.124690\n",
            "9           18             0.04        extra_trees  0.042553  2.351679\n",
            "23          19             0.02                mlp  0.049645  3.450804\n",
            "28          20             0.06       bernoulli_nb  0.070922  1.103046\n",
            "29          21             0.02                mlp  0.134752  2.500604\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(cls.show_models(), indent=4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TI-I2zRGbbMR",
        "outputId": "0dfe1adf-94ad-4170-b712-34f2e791db50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{   2: {   'balancing': Balancing(random_state=1),\n",
            "           'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7ff78ca32fa0>,\n",
            "           'cost': 0.028368794326241176,\n",
            "           'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7ff78ca32d30>,\n",
            "           'ensemble_weight': 0.04,\n",
            "           'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7ff78ca32160>,\n",
            "           'model_id': 2,\n",
            "           'rank': 1,\n",
            "           'sklearn_classifier': RandomForestClassifier(max_features=5, n_estimators=512, n_jobs=1,\n",
            "                       random_state=1, warm_start=True)},\n",
            "    3: {   'balancing': Balancing(random_state=1),\n",
            "           'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7ff78c996160>,\n",
            "           'cost': 0.028368794326241176,\n",
            "           'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7ff78c8c4400>,\n",
            "           'ensemble_weight': 0.12,\n",
            "           'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7ff78c996df0>,\n",
            "           'model_id': 3,\n",
            "           'rank': 2,\n",
            "           'sklearn_classifier': MLPClassifier(activation='tanh', alpha=0.0001363185819149026, beta_1=0.999,\n",
            "              beta_2=0.9, early_stopping=True,\n",
            "              hidden_layer_sizes=(115, 115, 115),\n",
            "              learning_rate_init=0.00018009776276177523, max_iter=32,\n",
            "              n_iter_no_change=32, random_state=1, verbose=0, warm_start=True)},\n",
            "    5: {   'balancing': Balancing(random_state=1, strategy='weighting'),\n",
            "           'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7ff78aeb85e0>,\n",
            "           'cost': 0.03546099290780147,\n",
            "           'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7ff78ca32310>,\n",
            "           'ensemble_weight': 0.04,\n",
            "           'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7ff78c653940>,\n",
            "           'model_id': 5,\n",
            "           'rank': 3,\n",
            "           'sklearn_classifier': RandomForestClassifier(criterion='entropy', max_features=3, min_samples_leaf=2,\n",
            "                       n_estimators=512, n_jobs=1, random_state=1,\n",
            "                       warm_start=True)},\n",
            "    7: {   'balancing': Balancing(random_state=1),\n",
            "           'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7ff78aecf9a0>,\n",
            "           'cost': 0.014184397163120588,\n",
            "           'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7ff78c6eaa90>,\n",
            "           'ensemble_weight': 0.1,\n",
            "           'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7ff78aecf790>,\n",
            "           'model_id': 7,\n",
            "           'rank': 4,\n",
            "           'sklearn_classifier': ExtraTreesClassifier(max_features=34, min_samples_leaf=3, min_samples_split=11,\n",
            "                     n_estimators=512, n_jobs=1, random_state=1,\n",
            "                     warm_start=True)},\n",
            "    8: {   'balancing': Balancing(random_state=1, strategy='weighting'),\n",
            "           'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7ff78ac1efa0>,\n",
            "           'cost': 0.03546099290780147,\n",
            "           'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7ff78c890160>,\n",
            "           'ensemble_weight': 0.02,\n",
            "           'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7ff78ad1d610>,\n",
            "           'model_id': 8,\n",
            "           'rank': 5,\n",
            "           'sklearn_classifier': RandomForestClassifier(max_features=2, min_samples_leaf=2, n_estimators=512,\n",
            "                       n_jobs=1, random_state=1, warm_start=True)},\n",
            "    9: {   'balancing': Balancing(random_state=1, strategy='weighting'),\n",
            "           'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7ff78aa0fd90>,\n",
            "           'cost': 0.04255319148936165,\n",
            "           'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7ff78c664a90>,\n",
            "           'ensemble_weight': 0.04,\n",
            "           'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7ff78ab7b610>,\n",
            "           'model_id': 9,\n",
            "           'rank': 6,\n",
            "           'sklearn_classifier': ExtraTreesClassifier(max_features=9, min_samples_split=10, n_estimators=512,\n",
            "                     n_jobs=1, random_state=1, warm_start=True)},\n",
            "    10: {   'balancing': Balancing(random_state=1, strategy='weighting'),\n",
            "            'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7ff78a920160>,\n",
            "            'cost': 0.028368794326241176,\n",
            "            'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7ff78ae93d00>,\n",
            "            'ensemble_weight': 0.02,\n",
            "            'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7ff78a992b50>,\n",
            "            'model_id': 10,\n",
            "            'rank': 7,\n",
            "            'sklearn_classifier': RandomForestClassifier(criterion='entropy', max_features=4, min_samples_split=6,\n",
            "                       n_estimators=512, n_jobs=1, random_state=1,\n",
            "                       warm_start=True)},\n",
            "    11: {   'balancing': Balancing(random_state=1),\n",
            "            'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7ff78a6ea0a0>,\n",
            "            'cost': 0.028368794326241176,\n",
            "            'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7ff78ac7a910>,\n",
            "            'ensemble_weight': 0.02,\n",
            "            'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7ff78a78ea90>,\n",
            "            'model_id': 11,\n",
            "            'rank': 8,\n",
            "            'sklearn_classifier': RandomForestClassifier(criterion='entropy', max_features=23, min_samples_leaf=7,\n",
            "                       n_estimators=512, n_jobs=1, random_state=1,\n",
            "                       warm_start=True)},\n",
            "    12: {   'balancing': Balancing(random_state=1),\n",
            "            'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7ff78a551a30>,\n",
            "            'cost': 0.03546099290780147,\n",
            "            'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7ff78ab5deb0>,\n",
            "            'ensemble_weight': 0.02,\n",
            "            'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7ff78a5514c0>,\n",
            "            'model_id': 12,\n",
            "            'rank': 9,\n",
            "            'sklearn_classifier': HistGradientBoostingClassifier(early_stopping=True,\n",
            "                               l2_regularization=0.005326508887463406,\n",
            "                               learning_rate=0.060800813211425456, max_iter=512,\n",
            "                               max_leaf_nodes=6, min_samples_leaf=5,\n",
            "                               n_iter_no_change=5, random_state=1,\n",
            "                               validation_fraction=None, warm_start=True)},\n",
            "    13: {   'balancing': Balancing(random_state=1, strategy='weighting'),\n",
            "            'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7ff788c6a040>,\n",
            "            'cost': 0.028368794326241176,\n",
            "            'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7ff78a824b20>,\n",
            "            'ensemble_weight': 0.02,\n",
            "            'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7ff78a096f40>,\n",
            "            'model_id': 13,\n",
            "            'rank': 10,\n",
            "            'sklearn_classifier': HistGradientBoostingClassifier(early_stopping=False,\n",
            "                               l2_regularization=1.0647401999412075e-10,\n",
            "                               learning_rate=0.08291320147381159, max_iter=512,\n",
            "                               max_leaf_nodes=39, n_iter_no_change=0,\n",
            "                               random_state=1, validation_fraction=None,\n",
            "                               warm_start=True)},\n",
            "    14: {   'balancing': Balancing(random_state=1),\n",
            "            'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7ff7889a0e20>,\n",
            "            'cost': 0.028368794326241176,\n",
            "            'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7ff78a692280>,\n",
            "            'ensemble_weight': 0.02,\n",
            "            'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7ff7889ec940>,\n",
            "            'model_id': 14,\n",
            "            'rank': 11,\n",
            "            'sklearn_classifier': MLPClassifier(activation='tanh', alpha=2.5550223982458062e-06, beta_1=0.999,\n",
            "              beta_2=0.9, hidden_layer_sizes=(54, 54, 54),\n",
            "              learning_rate_init=0.00027271287919467994, max_iter=256,\n",
            "              n_iter_no_change=32, random_state=1, validation_fraction=0.0,\n",
            "              verbose=0, warm_start=True)},\n",
            "    16: {   'balancing': Balancing(random_state=1, strategy='weighting'),\n",
            "            'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7ff78898a100>,\n",
            "            'cost': 0.021276595744680882,\n",
            "            'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7ff78a08d0d0>,\n",
            "            'ensemble_weight': 0.1,\n",
            "            'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7ff7889cef40>,\n",
            "            'model_id': 16,\n",
            "            'rank': 12,\n",
            "            'sklearn_classifier': HistGradientBoostingClassifier(early_stopping=True,\n",
            "                               l2_regularization=3.387912939529945e-10,\n",
            "                               learning_rate=0.30755227194768237, max_iter=128,\n",
            "                               max_leaf_nodes=60, min_samples_leaf=39,\n",
            "                               n_iter_no_change=18, random_state=1,\n",
            "                               validation_fraction=None, warm_start=True)},\n",
            "    17: {   'balancing': Balancing(random_state=1),\n",
            "            'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7ff7887c8760>,\n",
            "            'cost': 0.03546099290780147,\n",
            "            'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7ff788a47a00>,\n",
            "            'ensemble_weight': 0.02,\n",
            "            'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7ff78881d970>,\n",
            "            'model_id': 17,\n",
            "            'rank': 13,\n",
            "            'sklearn_classifier': HistGradientBoostingClassifier(early_stopping=True,\n",
            "                               l2_regularization=0.4635442279519353,\n",
            "                               learning_rate=0.09809681787962342, max_iter=512,\n",
            "                               max_leaf_nodes=328, min_samples_leaf=2,\n",
            "                               n_iter_no_change=2, random_state=1,\n",
            "                               validation_fraction=None, warm_start=True)},\n",
            "    19: {   'balancing': Balancing(random_state=1, strategy='weighting'),\n",
            "            'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7ff7883f0dc0>,\n",
            "            'cost': 0.028368794326241176,\n",
            "            'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7ff7889fd5b0>,\n",
            "            'ensemble_weight': 0.04,\n",
            "            'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7ff7883f0cd0>,\n",
            "            'model_id': 19,\n",
            "            'rank': 14,\n",
            "            'sklearn_classifier': ExtraTreesClassifier(criterion='entropy', max_features=448, min_samples_leaf=2,\n",
            "                     min_samples_split=20, n_estimators=512, n_jobs=1,\n",
            "                     random_state=1, warm_start=True)},\n",
            "    21: {   'balancing': Balancing(random_state=1),\n",
            "            'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7ff7883526a0>,\n",
            "            'cost': 0.021276595744680882,\n",
            "            'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7ff7888f4eb0>,\n",
            "            'ensemble_weight': 0.04,\n",
            "            'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7ff788352400>,\n",
            "            'model_id': 21,\n",
            "            'rank': 15,\n",
            "            'sklearn_classifier': ExtraTreesClassifier(criterion='entropy', max_features=4, min_samples_leaf=2,\n",
            "                     min_samples_split=15, n_estimators=512, n_jobs=1,\n",
            "                     random_state=1, warm_start=True)},\n",
            "    22: {   'balancing': Balancing(random_state=1),\n",
            "            'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7ff78810b7c0>,\n",
            "            'cost': 0.028368794326241176,\n",
            "            'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7ff78883ad30>,\n",
            "            'ensemble_weight': 0.12,\n",
            "            'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7ff7882ff610>,\n",
            "            'model_id': 22,\n",
            "            'rank': 16,\n",
            "            'sklearn_classifier': HistGradientBoostingClassifier(early_stopping=True,\n",
            "                               l2_regularization=8.057778875694463e-05,\n",
            "                               learning_rate=0.09179220974965213, max_iter=256,\n",
            "                               max_leaf_nodes=200, n_iter_no_change=18,\n",
            "                               random_state=1,\n",
            "                               validation_fraction=0.14295295806077554,\n",
            "                               warm_start=True)},\n",
            "    23: {   'balancing': Balancing(random_state=1, strategy='weighting'),\n",
            "            'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7ff787f04040>,\n",
            "            'cost': 0.049645390070921946,\n",
            "            'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7ff7884009d0>,\n",
            "            'ensemble_weight': 0.02,\n",
            "            'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7ff787efae20>,\n",
            "            'model_id': 23,\n",
            "            'rank': 17,\n",
            "            'sklearn_classifier': MLPClassifier(alpha=0.02847755502162456, beta_1=0.999, beta_2=0.9,\n",
            "              hidden_layer_sizes=(123, 123),\n",
            "              learning_rate_init=0.000421568792103947, max_iter=256,\n",
            "              n_iter_no_change=32, random_state=1, validation_fraction=0.0,\n",
            "              verbose=0, warm_start=True)},\n",
            "    26: {   'balancing': Balancing(random_state=1),\n",
            "            'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7ff787e62fa0>,\n",
            "            'cost': 0.028368794326241176,\n",
            "            'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7ff788341940>,\n",
            "            'ensemble_weight': 0.02,\n",
            "            'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7ff787e62d90>,\n",
            "            'model_id': 26,\n",
            "            'rank': 18,\n",
            "            'sklearn_classifier': ExtraTreesClassifier(criterion='entropy', max_features=414, min_samples_leaf=2,\n",
            "                     min_samples_split=19, n_estimators=512, n_jobs=1,\n",
            "                     random_state=1, warm_start=True)},\n",
            "    27: {   'balancing': Balancing(random_state=1, strategy='weighting'),\n",
            "            'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7ff787d3c610>,\n",
            "            'cost': 0.014184397163120588,\n",
            "            'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7ff78818f370>,\n",
            "            'ensemble_weight': 0.1,\n",
            "            'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7ff787d3c400>,\n",
            "            'model_id': 27,\n",
            "            'rank': 19,\n",
            "            'sklearn_classifier': ExtraTreesClassifier(max_features=134, min_samples_leaf=12, min_samples_split=4,\n",
            "                     n_estimators=512, n_jobs=1, random_state=1,\n",
            "                     warm_start=True)},\n",
            "    28: {   'balancing': Balancing(random_state=1, strategy='weighting'),\n",
            "            'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7ff787c11580>,\n",
            "            'cost': 0.07092198581560283,\n",
            "            'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7ff787f04bb0>,\n",
            "            'ensemble_weight': 0.06,\n",
            "            'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7ff787c04b80>,\n",
            "            'model_id': 28,\n",
            "            'rank': 20,\n",
            "            'sklearn_classifier': BernoulliNB(alpha=0.011056975175744176)},\n",
            "    29: {   'balancing': Balancing(random_state=1, strategy='weighting'),\n",
            "            'classifier': <autosklearn.pipeline.components.classification.ClassifierChoice object at 0x7ff7878ae520>,\n",
            "            'cost': 0.13475177304964536,\n",
            "            'data_preprocessor': <autosklearn.pipeline.components.data_preprocessing.DataPreprocessorChoice object at 0x7ff787e2d0d0>,\n",
            "            'ensemble_weight': 0.02,\n",
            "            'feature_preprocessor': <autosklearn.pipeline.components.feature_preprocessing.FeaturePreprocessorChoice object at 0x7ff7878ae130>,\n",
            "            'model_id': 29,\n",
            "            'rank': 21,\n",
            "            'sklearn_classifier': MLPClassifier(alpha=0.0007119897774330087, beta_1=0.999, beta_2=0.9,\n",
            "              hidden_layer_sizes=(51, 51, 51),\n",
            "              learning_rate_init=0.00028079049815589414, max_iter=256,\n",
            "              n_iter_no_change=32, random_state=1, validation_fraction=0.0,\n",
            "              verbose=0, warm_start=True)}}\n"
          ]
        }
      ]
    }
  ]
}